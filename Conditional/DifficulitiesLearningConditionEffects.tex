\documentclass[../Master.tex]{subfiles}
\providecommand{\master}{..}

\begin{document}

In STRIPS-Style actions the objects $A(O_1,O_2,\ldots,O_{n-1},O_n)$ are the only objects affected by the action.
Thus any predicate that contains objects other than $O_1,O_2,\ldots,O_{n-1},O_n$ can be discarded as irrelevant when learning either the effects or the preconditions.
However as actions with conditional effects support the use of quantifiers this claim no longer holds.
Therefore the universe $\mathbb{CP}$ for conditional effects of possible predicates is infinite as quantifiers can have an infinite number of variables.
However if the environment is \textbf{fully observable} and has a finite number of objects,
we can limit the variables of the quantifier to be equal to the number of objects; This means that we can limit $\mathbb{CP}$ to a finite set.
This is important as we now have an initial assumption of possible predicates for both the preconditions and the effects.

%\subsubsection{Limitations}
In order to simplify the problem we have made the following restrictions on conditional effects we can learn:
\begin{enumerate}[label=R.\arabic*]
	\item Environment must be fully observable.
	\item Environment must contain a finite number of objects.
	\item \label{rst:ca:no-disjuntive-conditionals} No disjunctive preconditions or effects.
	\item \label{rst:ca:no-multiple-effect} No multiples of the same effect.

		  I.E. the effect $\forall_x p(x) \land q(x)$ is supported, but $\forall_{x, y} p(x, y) \land p(x, x) $ is not.

	\item \label{rst:ca:no-disjoint-preconditions} No disjoint preconditions.

		  A disjoint precondition is when it is not connected to an effect or another non-disjoint precondition through its variables.
		  I.E. If a conditional effect had the effect $p(x)$ a disjoint precondition could be $p(y)$ as $x \neq y$ however if it also had a precondition $q(x,y)$ this would connect the two variables thus making $p(y)$ non-disjoint.
\end{enumerate}

Another aspect of conditional effects is the notion of multiple different effects in the same action. This is supported given that it does not break restriction~\ref{rst:ca:no-disjuntive-conditionals}; which it does if two conditional effects have the same effect, as that is equivalent to an disjunctive precondition.

In this section we will show how to approach the concept of learning conditional effect. We will show what problems that occur using prior models and what changes to the models are necessary in order to find proper solutions.

\begin{figure}
	\centering{%
	\includegraphics[width=0.5\textwidth]{\master/Graphics/house_conditional_knowledge.png}}
	\caption{\label{fig:ca:house-example}Three states of light problem for Example~\ref{ex:ca:light-on}}
\end{figure}

\begin{example}\label{ex:ca:light-on}
Consider the problem of turning on light as shown in \figref{fig:ca:house-example}.
In the figure there are three different cases of a person learning how to turn on the
light. In the first two cases the agent successfully turns on the light while in the last nothing occurs.

In the first case we learn that to turn on the light there are these possible precondition:
\begin{itemize}
	\item There must be a sofa in the north-east corner.
	\item There must be a lamp in the north-west corner. With an agent on the same spot.
	\item There must be a table in the middle.
\end{itemize}
Even though we intuitively know that it is only the lamp which is the only required object in this room for the light to turn on, we cannot discard any of the other objects present as not being a precondition.
\end{example}

\subsubsection{Preconditions from states}
Objects are defined by the predicates which they satisfy. As such when we say that all objects are assumed to be possible preconditions for specific effects to occur, what we are actually saying is that a specific composition of predicates is the requirement for the effects to occur.


This means if we interpret the objects as variables connecting the predicates in a pattern, then we can get an initial set of preconditions by using the state S which led to the effects. In real terms interpreting objects as variables means mapping each object 
to a to different variable.
\begin{align}
	&\sigma : P, \delta \leftarrow \left\{p\left(\delta(O_1),\ldots,\delta(O_n) \right) \mid p(O_1,\ldots,O_n) \in P  \right\}  &
\end{align}



For instance for the state
$\{ p(Object_1), p(Object_2),\ldots,p(Object_n)\}$ using a mapping
$\delta = \{Object_1 \mapsto x, Object_2 \mapsto y \ldots\}$
where $(x, y..)$ are variables for the quantifier of the conditional effect; Interpreting this state's objects as variables means to apply this mapping to the state's objects

$\{ p(\delta(Object_1)), p(\delta(Object_2)),\ldots,p(\delta(Object_n))\} = \{ p(x), p(y),\ldots\}$

\begin{theorem}\label{thm:ca:precondition-state}
If an action produces one or more effects $E$, then all predicates in the prior state are the maximum number of positive preconditions to those exact effects.

If $\gamma (S,a) \neq S$ and objects are interpreted as variables then $preconds(a) \subseteq S$  for effects $E$.

\begin{proof}[\textbf{Proof by contradiction}] Lets assume that there are more preconditions than present in S for the effects E.
	In this case the effects would not occur as their required preconditions are missing, thus the preconditions must be satisfied in S.
	As such we can conclude S contains at least all precondition predicates.    \qedhere
\end{proof}
\end{theorem}

\textbf{NB} For negative preconditions use $S^c$ where all predicates has been negated, as negative precondition refer to predicates not in the state.
Thus if both negative and positive preconditions are allowed a the same time use  $S \cup \neg[S^c] $ for the preconditions.

\begin{figure}
    \hspace*{0.1\textwidth}%
    \begin{subfigure}{0.35\textwidth}
        \centering
        \resizebox{\linewidth}{!}{\input{\master/Graphics/moveLeftBefore.pgf}}
        \caption{Before execution of \texttt{MoveLeft}}
    \end{subfigure}%
    \hspace*{0.1\textwidth}%
    \begin{subfigure}{0.35\textwidth}
        \centering
        \resizebox{\linewidth}{!}{\input{\master/Graphics/moveLeftAfter.pgf}}
        \caption{After execution of \texttt{MoveLeft}}
    \end{subfigure}
    \hspace*{0.1\textwidth}
	\caption{\label{fig:ca:sokoban-moveleft-action}\texttt{MoveLeft} action being used in a sokoban world for Example~\ref{ex:ca:sokoban-moveleft-action} }

\end{figure}

\begin{example}\label{ex:ca:sokoban-moveleft-action}
Let us consider an example of acquiring preconditions from a state modelled with predicates. In \figref{fig:ca:sokoban-moveleft-action} we see an example of an agent in the sokoban world pushing a box using a MoveLeft action with zero parameters.

The action schema that produced the effect is:
\begin{align*}
&MoveLeft():&  \\
&\quad
	\forall_{x, y}
		\left[
			\neg\texttt{sokobanAt}(y) \land \texttt{sokobanAt}(x)
		\right]
		\quad when \quad
		\left[ \texttt{adj-h}(x,y) \land \texttt{sokobanAt}(y) \right]& \\
&\quad
	\forall_{x, y, z, b}
		\left[ \neg\texttt{at}(b,y) \land \texttt{at}(b,x) \right]
		\quad when \quad
		\left[
			\begin{gathered}
				 \texttt{adj-h}(x,y) \land \texttt{adj-h}(y,z) \land \\
					  \texttt{sokobanAt}(z) \land \texttt{at}(b, y)
			\end{gathered}
		\right] &
\end{align*}

The state transition that occurred:

\begin{equation*}\label{eq:s_before}
S_{before} =
	\left\{
		\begin{gathered}
			\texttt{adj-h}(t1, t2), \texttt{adj-h}(t2, t3), \\
			\texttt{at}(box,t2), \texttt{sokobanAt}(t3)
		\end{gathered}
	\right\}
\end{equation*}
\begin{equation*}
S_{after} =
	\left\{
		\begin{gathered}
			\texttt{adj-h}(t1, t2), \texttt{adj-h}(t2, t3), \\
			\texttt{at}(box,t1), \texttt{sokobanAt}(t2)
		\end{gathered}
	\right\}
\end{equation*}
The effects of the state transition we calculate:
\begin{equation*}
\Delta S =
	\left\{
		\begin{gathered}
			\texttt{at}(box, t1), \texttt{sokobanAt}(t2), \\
			\neg\texttt{at}(box,t2), \neg\texttt{sokobanAt}(t3)
		\end{gathered}
	\right\}
\end{equation*}
To interpret the objects as variables we provide some mapping of objects to variables, such a mapping could be:
\begin{equation*}
\delta =
	\left [
		\begin{gathered}
			t1 \mapsto x \\
			t2 \mapsto y \\
			t3 \mapsto z \\
			box \mapsto b
		\end{gathered}
	\right ]
\end{equation*}
We apply the mapping to the objects of $S_{before}$:
\begin{equation*}
	\sigma(S_{before}, \delta) =
	\begin{gathered}
		\left\{
			\begin{gathered}
				\texttt{adj-h}(\delta (t1), \delta (t2)), \\
				\texttt{adj-h}(\delta (t2), \delta (t3)), \\
				\texttt{at}(\delta (box),\delta (t2)), \\
				 \texttt{sokobanAt}(\delta (t3))
			\end{gathered}
		\right\}
		=
		\left\{
			\begin{gathered}
				\texttt{adj-h}(x, y), \\
				 \texttt{adj-h}(y, z), \\
				\texttt{at}(y), \\
				\texttt{sokobanAt}(z)
			\end{gathered}
		\right\}
	\end{gathered}
\end{equation*}
We also apply the mapping to the effects $\Delta S$
\begin{equation*}
	\Delta S =
		\left\{
			\begin{gathered}
				\texttt{at}(\delta (box),\delta (t1)), \\
				\texttt{sokobanAt}(\delta (t2)), \\
				\neg\texttt{at}(\delta (box),\delta (t2)), \\
				 \neg\texttt{sokobanAt}(\delta (t3))
			\end{gathered}
		\right\}
		=
		\left\{
			\begin{gathered}
				\texttt{at}(b,x),
				\texttt{sokobanAt}(y), \\
				\neg\texttt{at}(b,y),
				\neg\texttt{sokobanAt}(z)
			\end{gathered}
		\right\}
\end{equation*}

The resulting fluent predicates are the preconditions and effects
Therefore our hypothesis of the action scheme is:
\begin{align*}
&MoveLeft_{hyp}():&  \\
&\quad
	\forall_{x, y, z, b}
		\left[
		\begin{gathered}
			\texttt{at}(b, x) \land \texttt{sokobanAt}(y) \land \\ \neg\texttt{at}(b,y) \land \neg\texttt{sokobanAt}(z) \quad
		\end{gathered}
		\right]
	when
		\left[
		\begin{gathered}
		\quad \texttt{adj-h}(x, y) \land \texttt{adj-h}(y, z) \land \\ \texttt{at}(b,y) \land \texttt{sokobanAt}(z)
		\end{gathered}
		\right]&
\end{align*}

According to theorem \ref{thm:ca:precondition-state} we can use $MoveLeft_{hyp}$ on $S_{before}$ and get $S_{after}$.
\begin{align*}
&\gamma(S_{before},MoveLeft_{hyp}) =
	\left\{
		\begin{gathered}
			\texttt{adj-h}(t1, t2), \texttt{adj-h}(t2, t3), \\
			\texttt{at}(box,t1), \texttt{sokobanAt}(t2)
		\end{gathered}
	\right\}
	= S_{after}
&
\end{align*}

We observe that this is indeed correct.


\end{example}




\subsubsection{Initial approach to reducing preconditions}
As different scenarios are explored the unproven set $U_p$ of preconditions can be reduced.
\newtheorem{thm-unknown-set}{Definition}
\begin{thm-unknown-set}
The unproven set $U_p$ is the preconditions which has neither been proven nor disproven, initially it contains all  predicates $\mathbb{CP}$.
\end{thm-unknown-set}

If we have the sets of unproven preconditions $U_p1$ and $U_p1$ from two different state transitions, we can compare them and remove discrepancies by intersection:

% Provided that we have the unknown preconditions $U_p$ of another state transition we can compare them and remove discrepancies.
%
% For two unknown precondition sets $U_p1$ and $U_p2$:

\begin{equation}
\label{eq:unknownpredcondset}
	U_p' = U_p1 \cap U_p2
\end{equation}

This will work for removing entire predicates and only if the two sets use exact same naming for variables. Herein lies the problem of reducing preconditions; unlike non-conditional effects where entire predicates are removed at a time, for conditional effects a reduction in the preconditions can simply mean the removal of a binding between two variables.
\begin{definition}
	A binding between variables, means that variables between predicates are the same.
	Bindings that contain only one variable are free and means that no binding exists.
	It is important to note that a predicate with multiple variables can have bindings with itself.
	For instance $q(x)$ and $p(x,y)$ has a binding on their first argument as they both refer to the same variable, and $y$ is a free variable as no other predicates with $y$ exists.
\end{definition}
Thus this approach to modelling the unknown preconditions, which we used for non-conditional actions is incorrect.

\begin{example}\label{ex:ca:light-on-2}
Following from Example \ref{ex:ca:light-on} we come to the second case in \figref{fig:ca:house-example}
we see that we can turn on the light again but this time the sofa and the lamp has changed location and
there is no table. From this we expand our knowledge by learning:
\begin{itemize}
	\item Sofa and lamp location does not matter
	\item A table is not needed
\end{itemize}
Its important to note that since we have not seen an absence of a sofa we cannot rule out that the presence of a sofa is a precondition for the light to turn on. This is important because it shows us that by trying different scenarios we reduce the incorrect preconditions.
\end{example}

\begin{example}\label{ex:ca:nonbinding-intersection-model}
To elucidate the problem of bindings further, imagine that we have two different $U_p$
\begin{align*}
&U_p1 = \{ \texttt{p}(x, x, x) \}
\end{align*}
\begin{align*}
&U_p2 = \{ \texttt{p}(x, x, y) \}
\end{align*}
We see that $U_p1$ has a stronger precondition, meaning that if $U_p1$ holds then so does $U_p2$ but not oppositely. I.E.
\begin{align*}
&\forall_{x} \texttt{p}(x, x, x) \nvDash \forall_{x, y} \texttt{p}(x, x, y)  \quad and \quad
 \forall_{x, y} \texttt{p}(x, x, y) \vDash \forall_{x} \texttt{p}(x, x, x)  &
\end{align*}
And if we were to take the intersection between the two sets then the resulting set would be the empty set which is incorrect. As they have the similarity of having the same binding between the first and second argument. What we actually need is to have a set of bindings and take the intersection of that.
\end{example}

\subsubsection{A new model: Binding sets}
As is evident our model of using set of predicates, that was used for modelling non-conditional effects, is not suitable when discussing conditional effects. As such we propose using Binding sets when modelling preconditions and effects for a conditional effect.

\begin{definition}\label{thm:ca:binding-set}
	Binding set $B$ is a theoretical set of all bindings which differentiate between bindings from different predicates, such that the name of predicates also determines whether or not two bindings are equal. Information pertaining to the name of the variable from which the binding exists does not conflict, therefore if two $B$ sets intersected but they had completely different naming of variables then the resulting set would still be as though their name matched.
	For instance $\{p(x,x), q(x,y)\} \cap \{p(y,x), q(y,x)\} = \{p(x,y), q(x,z)\}$, notice that in both they have a binding on the first argument, and that binding is kept when they are intersected, even though the naming of the binding was different.
\end{definition}
The problem with binding sets is that they are difficult to model if there are multiples of the same predicate. As we have restriction \ref{rst:ca:no-multiple-effect} this is not a problem for effects, but for preconditions this proves to be a major problem. However, as we only intend to use binding sets to explain the problems we will assume that ambiguous predicates are always correctly handled when a set operation is used.

Using binding sets we are now capable of getting a correct intersection of two possible precondition sets and get their common possible preconditions. The possible preconditions also known as the unknown set $U_p$, can always be turned into a binding set $B_p$.
And to get the remaining possible bindings between $B_p1$ and $B_p2$ and disproves all other bindings:

\begin{equation}
B_p' = B_p1 \cap B_p2
\end{equation}
This will unlike Equation \ref{eq:unknownpredcondset} correctly ignore variable naming, and be able to partially remove some of the restrictions on the predicate I.E. removing bindings, solving the problem demonstrated in Example \ref{ex:ca:nonbinding-intersection-model}.

\subsubsection{Proving preconditions}
Up until now we have only discussed limiting the number of possible preconditions (Unknown set) , however another aspect of learning is to determine what the actual preconditions are.
For non-conditional actions proving the preconditions of an action was a matter of using failed actions to make a list of candidate predicates that through elimination eventually got down to just one predicate which is then proclaimed proven. The approach is similar for conditional actions however instead of having candidates of predicates; conditional actions must maintain a candidate set for the bindings instead of entire predicates, and thus is only capable of proving a single binding at a time.

\begin{theorem}\label{thm:minimum-one-binding}
	If an action has been observed to produces an effect $E$, then if that effect does not occur in future transitions;
	a minimum of one binding in a predicate must be a precondition for that condition effect. Assuming restriction \ref{rst:ca:no-disjoint-preconditions} holds.

	\begin{proof}[\textbf{Proof by contradiction}] If there is less than one binding in the preconditions then that means there are zero bindings, if restriction \ref{rst:ca:no-disjoint-preconditions} holds then zero bindings means zero precondition. If there are zero preconditions then the effect would not have failed. Therefore there must be a minimum of one binding. \qedhere
	\end{proof}
\end{theorem}

Initially we have a binding set $B_u$, which is our set of unproven preconditions for the effect of an action.
If we then see that an effect does not occur in the state, the bindings in the prior state that did not produce that effect becomes the candidates of possible bindings $B_c$.

Because of Theorem \ref{thm:minimum-one-binding} the following invariant holds:
\begin{equation} \label{eq:binding_invariant}
\left| \{b  \mid  b \in B_c \land b \in preconds_{bindings}(A)\} \right|  \ge 1
\end{equation}


Meaning that at least one of the bindings in this set is part of the bindings in the preconditions for the action $A$. As bindings that are not contained in $B_u$ is disproven, we can filter disproven candidates by:
\begin{equation}
B_c' = B_c \cap B_u
\end{equation}
And thus if ever $|B_c| = 1$ then we know that it is a correct binding because of our Invariant \ref{eq:binding_invariant} and thus it is proven.

 \begin{example}\label{ex:ca:light-on-3}
 Consider the last case on \figref{fig:ca:house-example}. This case is identical
to the first case except it does not have a lamp, thus we learn that:
\begin{itemize}
	\item A lamp is required for the effect to occur.
\end{itemize}
Up until this transition we have not seen proof that the lamp was a precondition even though it would be intuitive for a human that still
does not mean that we can simply assume it could be that the person's action simply creates a
lamp which it then proceeds to turn on, and it was the case that no
lamp was created since it was present already.
Interestingly like with non-conditional preconditions we require failed actions to determine the actual preconditions but unlike non-conditional preconditions an action can both succeed and fail in the same step. For instance the light was successfully turned on for the lamp but it was unsuccessful in turning on the light for the sofa.

\end{example}

\end{document}
