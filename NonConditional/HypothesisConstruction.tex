\documentclass[../Master.tex]{subfiles}
\providecommand{\master}{..}
\begin{document}


	Up until now we have only discussed how to acquire knowledge about the action schemas, but it is equally important to discuss how to utilize the knowledge when construction an hypothetical action schema.
	We refer to this as hypothesis construction of the domain as we are making assumptions about what the domain could be.
	The design of the hypothesis determines the strategy of an agent, which impacts what it is capable of learning in the future.
	For instance if the hypothesis is based mostly on proven knowledge, the agent will never experience an unfamiliar situation and thus will never learn something new.

	In Chapter~\ref{sec:Learning} we went through examples of different strategies in this section we will show how that can be put to practice for STRIPS-style action schema, and what it means to the action schema itself.
	Furthermore, this section will also show the dichotomy between using unproven preconditions and unproven effects and how to manipulate the traits of a given strategy by changing these.

	The knowledge we can construct these hypothetical action schemas from are the following: 
	For precondition construction:

	\begin{itemize}
		\item Disproven preconditions $D_P$
		\item Proven preconditions $K_P$
		\item Unproven preconditions $U_P$ as $U_P = \mathbb{P} \setminus (K_P \cup D_P)$
		\item Candidates preconditions $C_P$
	\end{itemize}

	and for effect construction:

	\begin{itemize}
		\item Disproven effects $D_E$
		\item Proven effects $K_E$
		\item Unproven effects $U_E$ as $U_E = \mathbb{P} \setminus (K_E \cup D_E)$
	\end{itemize}

\subsubsection{Trait: Explorative/Exploitative}

	The explorative trait defines that the agent will prefer to explore all viable options to achieve the shortest possible path, at the cost of exploring incorrect solutions.
	In STRIPS-style planning terms this means the strategy will rely mostly on unproven effects in its hypothesis.
	It is explorative because it increases the probability of finding the most optimal plan to solve the problem,
	but in doing so increases the risk of making plan-prediction mistakes(PPM).
	\begin{quotation}
				A plan-prediction mistake occurs when an
				agent chooses a plan for a given episode that will not reach
				the goal, or asserts “no plan” when the goal is reachable. \cite{Walsh2008}
	\end{quotation}
	To distinguish between the two types of plan-prediction mistakes we define them as:

	\begin{definition} 
		[F-PPM] Faulty-plan plan-prediction mistake, is a PPM where the goal was not reachable using the plan.
	\end{definition}
	\begin{definition}
		[N-PPM] No-plan plan-prediction mistake, is a PPM where no plan was provided when the goal is reachable.
	\end{definition}
	An exploitative strategy means the agent will prefer not to try new actions as much as possible.
	In action schema terms this means the strategy will focus mainly on limiting unproven effects as much as possible.
	By limiting unproven effects the plans generated by the action schema, will be as close to reality as possible.




\subsubsection{Trait: Self-sufficient/Help-seeking}

	For explorative/exploitative strategies the difference was in whether the agent accepted the risk of making F-PPMs.
	Self-sufficient/Help-seeking strategies are determined on whether the agent accepts making N-PPMs.

	As a strategy becomes more self-sufficient the risk of the hypothesis making N-PPMs diminishes, provided that the problem is solvable.
	Conversely as the agent becomes more help-seeking the risk of the hypothesis making N-PPMs increases.

	The help itself may come in a variety  of different mechanism.
	For instance, in \cite{Walsh2008} they proposed a teacher that for the an initial state $S_0$ and a goal $\mathcal{G}$ provides all the transitions $(s,a,s') \in T$, where $T$ is a trace, which leads to the solution of $\mathcal{G}$,
	 thereby solving the problem for the agent when the it is incapable.
	The agent can then use this information to learn enough about the action schema, such that it can solve this exact goal in the future.
	As we primarily focus on learning through induction rather than deductive methods, we will assume that there exists such a mechanism that can teach a help-seeking agent;
	provided that the hypothesis gives "no plan" when help is required.

\subsubsection{Strategy: Pessimistic}

	A pessimistic strategy as we defined in~\ref{sec:Learning} has the traits always \texttt{Exploitative} and always \texttt{Help-seeking},
	meaning the hypothetical action schema should never make F-PPMs and claim "no plan" if it cannot guarantee the solution.

	In \cite{Walsh2008} they suggest the following for a pessimistic learning strategy
	
	\begin{quotation}
		Our strategy in
		this setting revolves around the use of a pessimistic model
		where a.PRE and a.DEL contain all the fluents that have
		not been disproved, and no fluents are in a.ADD unless directly
		evinced.
	\end{quotation}
	 
	They do this under the assumption that negative preconditions cannot occur and that negative goals are not present. As we do not have these restrictions, an identical implementation of their method would not suffice, as it could introduce F-PPMs. For instance, planning with an action which is incorrectly believed to have a negative effect can cause another action with negative preconditions to be perceived as applicable by the planner.
	Additionally, a problem with their strategy, which we were unable to find an answer to, is the following: If we assume that "evinced" means proven, and not merely observed with ambiguity, then an agent can come in a state where a teacher shows a full trace but because certain effects was not proven, due to ambiguity, the agent would be incapable of reproducing the plan.
	
	\begin{example}
		To show how an agent cannot reproduce a plan, if it only uses proven effects.
		
		Assume we have an action.
		\begin{equation*}
			\begin{split}
				Action ~ A &(x, y) \\
					pre&: \{\} \\
					eff&: \{p(x,y)\}			
			\end{split}
		\end{equation*}
		
		and a STRIPS-style domain.
		\begin{equation*}
			\begin{split}
				\mathbb{P} &= \{p(x,y), p(y,x), p(x,x), p(y,y)\}		\\
				Objects~O &= \{o_1,o_2,...,o_{n-1},o_n\} \\
				Goal~\mathcal{G} &= \{p(o_1,o_1)\} \\
				S_0 &=\{\}
			\end{split}
		\end{equation*}
		
		Initially the teacher would provide the agent with the following trace
		
		\begin{equation*}
			\begin{split}				
				Trace~T &= (S_0,A(o_1,o_1),S_1) \\
				S_1 &= \{p(o_1,o_1)\}				
			\end{split}
		\end{equation*}
		
		However because the action used was $A(o_1,o_1)$ neither of the predicates in $\mathbb{P}$ can be proved as effects, as it could have been any of those given all we observe is $\{p(o_1,o_1)\}$. 
		As such if we used the pessimistic action schema proposed by \cite{Walsh2008}, no effects would be added to the hypothetical action schema, and therefore the agent would unable to reproduce the plan. 
		
		Lastly it is important to note that using all the unproven effects instead would not result in a PPM as they all become $\{p(o_1,o_1)\}$ when applied.
		
	\end{example}
	
	A solution to the problem of being unable to solve a solved problem, we suggest a pessimistic action schema where effects include both all non-disproved negative effect along with the non-disproved positive effects.
	As such this solution would be:
		\begin{equation}
			\begin{split}			
				preconditions&= \bigwedge\limits_{k \in K_P \cup U_P} k \\
				effects&=  K_E \cup U_E
			\end{split}
		\end{equation}
	This approach will allow negative goals along with negative preconditions. 
	However because this hypothesis uses unproven effects, there is a chance that if certain preconditions are disproven, that would allow it to be applied where the unproven effects actually does change the outcome.
	As such it could make a F-PPM, but it is necessary if we want it to be able to reproduce plans. 
	Therefore in conclusion this action schema hypothesis would be mostly \texttt{Exploitative} and mostly \texttt{Help-seeking}.
	
	

\subsubsection{Strategy: Optimistic} 

	An optimistic strategy has the traits \texttt{Explorative} and \texttt{Self-sufficient},
	this means the hypothetical action schema is allowed to make F-PPMs but never allowed to make N-PPMs.

	In \cite{Walsh2008} they constructed the action schema's preconditions by iterating through all subset of non-disproved preconditions.
	This is accomplished by selecting one subset of the non-disproved preconditions and use that until the planner returns "no plan" and thereafter discarding it along with precondition subsets that satisfied it.

	We propose that preconditions are constructed based on our knowledge instead.
	The candidates $C$ contain information about single instances of precondition combinations that has been shown to give a failure;
	thus by placing them in CNF in the action schema we guarantee that states which contain those specific predicate combination cannot have the action applied to it.
	Furthermore, we have the $K_P$ that contain the proven preconditions, as such combining the two we get:

	\begin{equation} \label{eq:nca:opt-preconds}
		preconditions = \bigwedge\limits_{k \in K_P} k \quad \land \quad  \bigwedge \limits_{c \in C_P} \left( \bigvee \limits_{p \in c} p\right)
	\end{equation}

	Notice that this requires the planner to support disjunctive preconditions.

	For effects \cite{Walsh2008} proposed to use all non-disproven positive effects when constructing the action schema. 
	This approach will only allow the agent to solve positive goals.
	To allow both positive and negative goals to be solved, we propose to use the negative non-disproven effects as well when constructing the action schema.

	\begin{equation}
		effects =  K_E \cup U_E
	\end{equation}

    In order for this to work the planner must support three valued logic \cite{putnam1957a}, or planning with spurious actions (see~\cite{Russell}).
	Such a planner would, when encountering an effect $p$ in an effect set $E$ that is to be added and deleted (is spurious), add it to a special undefined set $\mathcal{X}$.
	If however the effect is not spurious meaning it is either positive or negative then it is removed from $\mathcal{X}$.

			\begin{equation}
				\begin{split}
					Spurious~E_S &= \{ p \mid p \in E \land \neg p \in E \} \\
					Non\text{-}Spurious~E_{NS} &= \{ p \mid (p \in E \land \neg p \notin E ) \lor (p \notin E \land \neg p \in E )  \}\\
					Undefined~set~\mathcal{X}' &= \mathcal{X} \cup E_S \setminus E_{NS}
				\end{split}
			\end{equation}
	For the purposes of checking whether the goal is solved, each predicate in $\mathcal{X}$ is considered as both being positive and negative.
	For instance if the goal is $\mathcal{G} = \{at(t1), \neg at(t2)\}$ and $\mathcal{X} = \{at(t1), at(t2)\}$ then that goal is deemed solved by the planner.

	\begin{example}
		This example will show how to construct an optimistic hypothesis, using knowledge from a sokoban domain.
		Assume we have the following knowledge for action an \texttt{move-h}:
		 	\begin{equation*}
			 	\begin{split}
				 	K_P & = \left\{\texttt{hAdj}(from, to) \right\} \\
					C_P& =	\left\{
							\begin{gathered}
								\left\{
								\begin{gathered}
									\texttt{hAdj}(to, from), \\
									\neg\texttt{hAdj}(from, from), \neg\texttt{hAdj}(to, to)
								\end{gathered}
								\right\},	\\ \left\{
								\begin{gathered}
									\texttt{sokobanAt}(from), \texttt{clear}(to)
								\end{gathered}
								\right\}
							\end{gathered}
							\right\}
				 	\\
				 	K_E& =
						 	\left\{
						 	\begin{gathered}
							 	\neg\texttt{sokobanAt}(from)
						 	\end{gathered}
						 	\right\}
					\\
				 	U_E& =
					 	\left\{
					 	\begin{gathered}
						 	\texttt{sokobanAt}(to),
						 	\texttt{clear}(to)
					 	\end{gathered}
					 	\right\}
				\end{split}
		 	\end{equation*}

		The optimistic hypothesis for $\texttt{move-h}$ would thus be:
			\begin{equation*}
				\begin{split}
					Preconds& :\left(
									 \begin{gathered}
									   \texttt{hAdj}(to, from) ~ \lor \\
									  \neg\texttt{hAdj}(from, from) ~ \lor \\ \neg\texttt{hAdj}(to, to)
									 \end{gathered}
								  \right) \land
								  \left(
									  \begin{gathered}
										  \texttt{sokobanAt}(from) ~ \lor \\ \texttt{clear}(to)
									  \end{gathered}
								  \right) \land \texttt{hAdj}(from, to) \\
					Effects &: 	\left\{
									\begin{gathered}
										\neg\texttt{sokobanAt}(from),
										\texttt{sokobanAt}(to),
										\texttt{clear}(to)
									\end{gathered}
								\right\}
				\end{split}
			\end{equation*}
	\end{example}

\subsubsection{Strategy: Confident}

A Confident strategy, as we have defined it, have the traits \texttt{Exploitative} and \texttt{Self-sufficient},
this means the hypothetical action schema will avoid both making F-PPMs and N-PPMs. 

To accomplish this, our hypothesis will only use preconditions that have been proven.
For effect construction, it will initially use many predicates while the agent is ignorant, and fewer as it becomes more knowledgeable. 

The preconditions \eqref{eq:nca:opt-preconds} from the optimistic strategy will suffice for this purpose, and obviously the requirements for the planner will remain the same.

For the effects we propose to use unproven and proven effects for an action with the removal of proven effects from other actions. 
As such this strategy unlike the other strategies takes into account all actions of the agent.
Let $K_{E_1},K_{E_2},\ldots,K_{E_n}$ be the proven effects of the other actions, thus the effects of the action in question would be.

\begin{equation}
		effects = \left( U_E \setminus \bigcup \limits_{i = 1} ^n K_{E_i} \right) \cup K_E
\end{equation}

This schema would be \texttt{Exploitative} in the sense that once one action was capable of producing an effect then no other action would be explored for that purpose. 
Furthermore, it is \texttt{Self-sufficient} because it will almost always produce some plan.

The problem with the confident strategy is very evident. If an inferior action is learned first, the agent will use that over exploring other options.

\end{document}
