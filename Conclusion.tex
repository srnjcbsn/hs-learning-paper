\documentclass[Master.tex]{subfiles}
\begin{document}

Throughout this thesis, we have explored the concepts of learning, including different methods for obtaining knowledge, strategies that guide the selection of actions, as well as different domain models that can be learned from.

We have shown that these concepts can be implemented by an algorithmization of the scientific method, from which we inherit the idea of experimenting to obtain data that can then be analysed to distill facts and falsities.

	Separate to the act of obtaining knowledge from observations is the concept of achieving situations that may accommodate learning, referred to as a learning strategy.
	Strategies are essential to the discussion of learning, 
	It is also an unavoidable feature of any intelligent agent, since that not having a strategy is a strategy itself. 


	Initially when one looks at learning from a purely non-conditional perspective, 
	it seems obvious to conclude that learning is just about the observation of contradictions,
	and is based purely on logical proofs, as we saw in our proof of non-conditional action learning.
	However the problem non-conditional action schemas is, for starters 
	these sort of domains are not a natural way of expressing actions, 
	usually actions contain conditional effects therefore these theory for learning them, 
	while interesting, may not be useful in actual environments.
	Furthermore, because actions that fail provides no feedback, 
	therefore performing that action for the first time can take an agent a very long time, as all candidate sets must be generated.
	
	For non-conditional actions we provided solutions that removed two of the restrictions outlined in \cite{Walsh2008} for their algorithms.
	First one is negative preconditions, our solution is fairly simple as we just had to consider the absence of atoms in the state.
	The problem however, is that usually only a small subset of all the possible atoms are in the state at the same time, 
	but with the introduction of negative preconditions, we have to consider all possible atoms all the time.
	Secondly we solved the problem with negative goals, the solution of extending the internal planner with a new feature --- planning with spurious actions --- is in our opinion quite ingenious, as it is very simple to implement. 
	
	
	When we move into the domain of conditional action learning --- which is much closer to the real world --- 
	then the problem is more related to pattern recognition than to logic, this makes sense as machine learning as a field is based on the field of pattern recognition. 
	The underlying truth is that we as logicians often think of preconditions as just that, conditions that must be satisfied in order for effects to happen, and while that is correct it would be more helpful to view them as patterns that allows for those effects.
	Once we change our view of logic formulas, to one based on mathematical models --- such as our hypergraph model ---	then comprehension of the problem no longer seems overwhelming but rather a manageable challenge. 
	
%	Why hypergraphs are so important to our solution, is that as a model it allows for nameless variables in the atoms. 
%	In normal first order logic nameless variables are not a particularly attractive feature, 
%	however as a knowledge description it allows us to compare two conditionals in a simplified manner.
	
	The hypergraph optimization that we have worked on adds the feature of combining many connecting paths that are overlapping into one single graph, which space complexity is not intractable.
	
	The problem currently with hypergraph model is that we have not solved the problem of isomorphic subgraphs (or subgraph matching) in the hypergraphs, 
	this is especially a problem for our merging algorithm (see \Cref{algo:hypergraphmerge}) as it currently have no prevention of these.
	Our opinion is that given these subgraphs are not incorrect knowledge but rather duplicate knowledge then removal of some of the subgraphs should be a significant improvement.
	Therefore using suboptimal solutions that run efficiently would suffice for our purpose. 
	However we have not had time to focus on this aspect, as we have focused on knowledge acquisition and utilization of that knowledge (construction of hypothesis).
	
	
	Overall we think that learning algorithms built as an deterministic algorithm as opposed to evolutionary algorithm, can be a viable approach to achieve a learning A.I. However further research is definitely required if we are to undercover all the aspects of what it means to learn.
	
	
	
	
	
	

	\section{Future Work}
	
	\begin{enumerate}
		\item Analyze expressive power of our conditional action with our restrictions.
		\item Research efficient models for permutations solving the problem of storing atoms and connecting paths.
		\item Solve the problem of isomorphic subgraphs in our proposed hypergraph merging algorithm.
	\end{enumerate}
	

\end{document}
