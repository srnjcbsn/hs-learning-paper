\providecommand{\master}{..}
\documentclass[../Master.tex]{subfiles}
\begin{document}

In order to discuss learning we must define a model for the domain which we operate within. We have chosen to use the generally accepted PDDL or Planning Domain Definition Language (see~\cite{PDDL}), as it is well researched.

This section will give a minimal definition of PDDL, and provide context for syntax used in later chapters. We will also explain functions used in state manipulation such as the grounding and state-transition functions.


PDDL is based on set-theoretic planning (see~\cite{ghallab2004a}) popularized by the STRIPS language (see~\cite{STRIPS}). By default states in PDDL are based on closed-world-assumption, meaning that if something is not defined in the state it is assumed to be false. 
In PDDL and set-theoretic planning, a state is set of grounded atoms defining the properties of the objects in an environment.

\begin{definition} 
	An intensional definition of a state $S$ in PDDL is a set of grounded atoms:
    \begin{equation*}
        S=\{p(o_1,\dots,o_n) \mid  p \in \preds \land \{o_1,\dots,o_n\} \subseteq \objs \land p(o_1,\dots,o_n) = \texttt{TRUE}\}
    \end{equation*}
    Where $\objs$ is the set of all objects in the world, and $\preds$ is the set of all predicates that can be used to describe the objects in the world.
\end{definition}

Since states are based on closed-world-assumption, they contain no negative atoms; however for the purpose of this thesis we would like to be able to represent a complete state which contain explicitly all the negative atoms. 
We define this explicit state as $X$, which is derived from its original state $S$.
\begin{definition} 
	Explicit state function $X(S)$ outputs the state where absent atoms become negative literals while maintaining the old atoms as positive literals. It is defined as follows: 
	
	\begin{equation*}
	X(S)=\{p \mid p \in S \} \cup \{\neg p \mid  p \notin S \}
	\end{equation*}
	\textbf{NB} For simplicity $S$ as a function argument can be omitted if implied through context. 
\end{definition}

The ways an agent can change the state, and under which circumstances, is described by \textit{action schemas}. 
	
\begin{definition} \label{def:lrn:action-spec-def}
		An action definition or action schema defines when an action is to be applied, as well as the consequences of the application. As such an action schema contains a logical formula specifying its preconditions, which must be satisfied for the action to be applied. If the preconditions are satisfied, the changes listed in the logic formula denoting the effects are applied. The structure of an action schema is the following:
	\begin{itemize}
        \item[Pre] A goal description (GD), explained below. : :
    \end{itemize}
    \begin{equation*}
		\begin{array}{ll}
		Action~schema~A: & \\
		
		\begin{array}{ll}
		Parameters & : (v_1,\dots,v_n) \\  
		Pre	& : Goal~Description \\
		Eff & : Effect 
		\end{array}
		\end{array}
    \end{equation*}

	The parameters of an action schema is a list of variables used in the Pre and Eff. Pre is description of the action schema preconditions and Eff is a description of its effects. 
    Goal Description or GD is a specifically designed logic formula for describing precondition. Effect is another logical construct for describing effects of an action.

		The BNF for GD and Effect is as follows:
		
	%DONT USE TABS on the following listing as it is directly affected by it
		\begin{lstlisting}
            <GD> -> <GD> and <GD>
            <GD> -> LITERAL
            
            
            <Effect> -> <Effect> and <Effect>
            <Effect> -> LITERAL
            <Effect> -> Forall <variable>* <Effect> 
            <Effect> -> <Effect> When <GD>
            
            <LITERAL> -> <predicate> (TERM*)
            <LITERAL> -> not <LITERAL>
            
            <TERM> -> <object>
            <TERM> -> <variable>
		\end{lstlisting}
		
		This is a limited definition of PDDL action schemas, however we have only defined what is required to understand this thesis.
	\end{definition}
	
In PDDL a set of action schemas, along with properties about always present objects and specifications of all Predicates are defined as a domain.

\begin{definition} A domain in PDDL, defines what predicates can be utilized, objects that are constant between all instantiations of the domain, and the action schemas available to the planner.
	
$
\begin{array}{ll}
Domain~\mathcal{D}: & \\

\begin{array}{ll}
Constants & = \{o_1,\dots,o_n\}			 \\  
Predicate-Specs = \preds \\
Action-Specs & = A~set~of~action~schemas~avaiable~to~the~agent \\
\end{array}
\end{array}$
\end{definition}


	

An application of an action contain the name of its corresponding action schema, and a list of objects that are to be mapped to its variables.
\begin{definition} 
	An action $A(o_1,\dots,o_n)$ explains how action schema $A$ is to be applied. The mapping to variables works like normal function application. 
	
	$\sigma = \{ v_1 \mapsto o_1,\dots,v_n \mapsto o_n \}$.
	
	For notational purposes, an application of an action schema $A$ can be written as:
	
	$a = A(o_1,\dots,o_n)$ 
	
	I.e. the name of the action schema in lower case, where the input to action is some combination of objects.
	
	
	
\end{definition}


Atom which contain only objects in its arguments are referred to as grounded atoms. Given a mapping $\sigma$ from variables to objects any atom can become a grounded atom.
\begin{definition} 
	Any atom can be mapped to a grounded atom, by a applying a mapping $\sigma$ to each of its arguments. As such the \ground function takes a atom $p$ and a mapping $\sigma$
	
		$\ground(p(x_1,\dots,x_n),\sigma) = p(\sigma(x_1),\dots,\sigma(x_n)$ where $p$ is the predicate.
		
	If the mapping is given in context, i.e. there is an action application in context of the discussion, then the shorthand $\ground(p)$ can be used instead.
\end{definition}


To explain how an action is applied to a state we define a State-Transition function in accordance with set-theoretic planning.


\begin{definition} 
	State-Transition function $\gamma$ takes two inputs a State $S$ and an Action $A$. Its exact definition is:

	$\gamma(S,A) \triangleq 
	\left\{
	\begin{array}{ll}
		(S \setminus effect^-(A)) \cup effect^+(A) & \mbox{if } A~is~applicable~to~S  \\		
		undefined & otherwise 
	\end{array}
	\right.$ 
	
	where $effect^+$ are the positive changes, meaning the grounded atoms that are to be set \texttt{TRUE} in the new state $S'$. Conversely $effect^-$ are the negatives changes, which are the atoms to be set \texttt{FALSE} in $S'$. 
	
	\textbf{NB} For more feature rich PDDL versions, the $effect$ functions require both the domain, problem and state in order to get the actual effects; however we assume these are given from context unless specified otherwise.
	
\end{definition}

Furthermore, we define a single Transition as follows:

\begin{definition} 
	Transition $T$ refers to a triple (S,A,S'), where S is the original state, A is the action that was applied S and S' is the resulting state.
\end{definition}

Lastly in order for an agent to know its purpose when planning it must have a defined goal. Such a goal is defined within a PDDL Problem.

\begin{definition} A problem contains the objects that is specific to the problem, the initial state of the planner and the goal expressed as a goal description (see Def.  \ref{def:lrn:action-spec-def}).
	
	$
	\begin{array}{ll}
	Problem ~ \mathcal{P}: & \\
	
	\begin{array}{ll}
	Objects ~ \objs & = \{o_1,\dots,o_n\}			 \\  
	Init\texttt{-}State~ S_0& = A ~ State\\
	Goal ~ \goal & = Goal ~ Description\footnote{Goal Description is identical to the one defined in Definition \ref{def:lrn:action-spec-def}.}
	\end{array}
	\end{array}$
\end{definition}

To use a PDDL specification an agent can with a domain and an accompanying problem generate a plan, which solves that specific problem.

\begin{definition} 
	A plan $P$ is defined as a list of action, solving a given problem.
	$P = (a_1,\dots,a_n)$
\end{definition}

Given this machinery an agent is thus capable of modeling the world and define actions that is applicable in the world. These definitions provides a framework for learning of action schema, which we will go into detail with, for both non-conditional and conditional action schemas.

\subsection*{Non-conditional vs Conditional actions}

As we will go in depth through out this paper how to achieve both non-conditional and conditional action learning, as such we want to establish the difference such that they can be properly discussed. 

A non-conditional action, as the name implies are actions which contain no conditional effects. This means that the effect of the action will always be the same. From a learning perspective this makes understanding the action easier because if an effect is observed then it is always guaranteed no matter the circumstances.  Specifically this means not using the $Forall$ and $When$ part of BNF for $<Effect>$, if those are not used then we define an action as being non-conditional. Conversely if those are used then an action is defined as being conditional.

Whether an action support conditional effects or not has a huge impact on how the action can be described. For instance, if the action that is being modelled actually contain conditional effect, then in order to model it as a non-conditional action it has to be described using multiple actions. This becomes evident in our Sokoban example which we will use throughout this thesis, where we see that pushing a box and moving an agent is two different actions even though in the video game it was modelled after this was just one action.

\section{Sokoban in PDDL}\label{sec:pddl:ss:soko:ds}
    \subfile{\master/Appendices/SokobanPDDL}
\end{document}
